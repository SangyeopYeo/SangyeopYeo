![header](https://capsule-render.vercel.app/api?type=rect&color=D3D3D3&height=150&section=header&text=Our%20paper%20is%20accepted%20on%20ECCV%202024.&fontSize=45&rotate=0&fontAlign=50&fontAlignY=50&descSize=25&descAlign=70&descAlignY=10)

## Notice
Title: (ECCV 2024) Nickel and Diming Your GAN: A Dual-Method Approach to Enhancing GAN Efficiency via Knowledge Distillation  
Website: https://sangyeopyeo.github.io/Nickel_and_Diming_Your_GAN/  
Authors: **<ins>Sangyeop Yeo</ins>**, Yoojin Jang, Jaejun Yoo

Thank you for your interest!
The code has been pre-released, but we are currently refining it, and the trained weights will be available soon.

## Hi guys! ğŸ‘‹
I'm sangyeop. I obtained B.S.(2021) degree from Electrical and Computer Engineering at Ajou University.

Currently, I'm a M.S. & Ph.D. course student at Laboratory of Advanced Imaging Technology (LAIT) in the Artificial Intelligence Graduate School (AIGS) at Ulsan National Institute of Science and Technology (UNIST), under the supervision of Prof.Jaejun Yoo.

My main research area lies at the intersection of ***multi-modal generative models*** and ***efficient, personalized generative models***.

I am very interested in understanding and expressing the world we live in. Generative models are a powerful way to model our world, and I have a strong interest in them to better express the real world. To achieve this, we need a deep understanding of the various modalities that make up the world, such as images, videos, 3D representations, language, and audio. I am particularly focused on multi-modal generative models that can effectively integrate these elements, and I also have a strong interest in foundation models to further enrich this expression.

Even if we model the world excellently, if only a few people can benefit from it, it cannot reach its true value. Therefore, I am also deeply interested in personalized generative models. In particular, my research focuses on computationally efficient and data-efficient generative models to address the cost challenges that pose significant barriers to personalization. Lightweight generative models and few-shot generation enable generative models to perform well in personal environments where computational resources and data are limited.

If you have a question about me, you can freely ask me anytime.

## Curriculum Vitae
[Curriculum Vitae](https://sangyeopyeo.github.io/assets/cv/Curriculum_Vitae.pdf)

## Tech Stack
<img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white"/> <img src="https://img.shields.io/badge/C%20(programming%20language)-A8B9CC?style=flat-square&logo=c&logoColor=white"/> <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white"/> <img src="https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white"/> <img src="https://img.shields.io/badge/Visual%20Studio%20Code-007ACC?style=flat-square&logo=visualstudiocode&logoColor=white"/> <img src="https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white"/> <img src="https://img.shields.io/badge/Anaconda-44A833?style=flat-square&logo=anaconda&logoColor=white"/>

## Research Interests
* Multi-modal generative models
  * image, video, 3D, language, and audio
* Efficient deep generative models
  * lightweight models, and few-shot learning and generation
* Foundation models

## Organization
* LAIT - https://github.com/LAIT-CVLab
<!--
## Experience
### ì°½ì˜ììœ¨ê³¼ì œ - ìš¸ì‚°ê³¼í•™ê¸°ìˆ ì› (Self-research challenges program for creativeity - UNIST)
Topic: Developing lightweight generative models
<details>
<summary>:point_up_2:Click for details</summary>
<div markdown="1">

The content is currently private!

</div>
</details>

### ìŠ¤ë§ˆì¼ê²Œì´íŠ¸ ë©¤ë²„ì‰½ - ìŠ¤ë§ˆì¼ê²Œì´íŠ¸ í“¨ì³ë© (Smilegate Membership - Smilegate Future LAB)
Topic: Face style editing via GAN 

Team profile: https://github.com/SGM-StyleTransfer

### AI Challengers Program - Uêµìœ¡í˜ì‹ ì„¼í„° (AI Challengers Program - U Innovative Education Center)
Topic: Interactive video style transfer

### BTS ì‹¤ì „ë¬¸ì œì—°êµ¬íŒ€ - ë¯¸ë˜ê¸°ìˆ í˜ì‹  ìœµí•©í˜• ì¸ì¬ì–‘ì„± ì‚¬ì—…ë‹¨ (Brain To Society Industry Friendly Research Project - Future Technology Innovation Convergence Talent Training Center)
Topic: Disease detection via medical image analysis
<details>
<summary>:point_up_2:Click for details</summary>
<div markdown="1">

![image](https://user-images.githubusercontent.com/84113554/193589640-c1517ac5-6e7e-4e6d-a166-446e7a962fa1.png)

</div>
</details>-->

## Publication :tada:
**Nickel and Diming Your GAN: A Dual-Method Approach to Enhancing GAN Efficiency via Knowledge Distillation**  
***<ins>Sangyeop Yeo</ins>**, Yoojin Jang, Jaejun Yoo*  
*European Conference on Computer Vision (ECCV), October 2024*  
*[project page](https://sangyeopyeo.github.io/Nickel_and_Diming_Your_GAN/) (First)*

**Can We Find Strong Lottery Tickets in Generative Models?**  
***<ins>Sangyeop Yeo</ins>**, Yoojin Jang, Jy-yong Sohn, Dongyoon Han, Jaejun Yoo*  
*Association for the Advancement of Artificial Intelligence (AAAI), February 2023*  
*[project page](https://sangyeopyeo.github.io/SLT-in-Generative-Models/) (First, Oral)*

## Contact ğŸ“«
Email: sangyeop377@gmail.com  
LinkdIn: 

<!--
**SangyeopYeo/SangyeopYeo** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
